better train data: 


- fix fluctuating loss
	- investigate
	- learning rate still too high? 

- regenerate data
- normalize data
- find out kick / snare volume or velocity... 
	- store that in the label data
	- if there are multiple, take diagonal as velocity

Try v2Funnel nochmal.
- 


- make funnels for audio events 
- schedule learn rate 0.001 => 0.00001 (over 50 epochs) 

////

- D: when training save model every x epochs
- D: weight buffers with events higher than others
- D: observe how it decreases to 0

Optimizing training etc: 
- Maybe I need shorter chunks (like 8s or 4s) 

Experimente
- D: Mono (Performance vorteil?) 

3) Application in the Browser

2) Training

- D: Exit when change in loss < threshold

- D: Use Pytorch for defining the model and training
- Try different architectures programmatically
  - cnn layers, features
  - rnn layers and size
  - training parameters
  - each to 20 epochs
  - then compare the 5 best in depth 
- Convert to ONNX 
- Use it in the browser with onnxruntime-web

1) Ground Truth

- Use data from Nighthawks annotated manually for fine tuning

- D: Damn! the ffmpeg speed filter I am using does not pitch down at the moment
  - D: Need to use samplerate instead

- D: Use data created from MIDI files for training
  - Keep the specific notes and programs (general MIDI sound set) variable
    - For a start
      - kick and 
      - snare
      - (flash can be overall FFT engergy or so) 
  - x2 by using different sound fonts

- D(more or less): In both cases: 
  - x5 by pitching up and down 2x
  - x3 by adding reverb
  - x3 by adding noise
    - white noise
    - some noise

- D: Cut out 10s pieces
  - sometimes combine one song with another
  - audio and kicks.txt and snare.txt

